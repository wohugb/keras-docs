



<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      <meta http-equiv="x-ua-compatible" content="ie=edge">
      
        <meta name="description" content="Keras，Python 深度学习库中文文档。">
      
      
        <link rel="canonical" href="http://keras.io/zh/2-Layers/5.recurrent/">
      
      
      
        <meta name="lang:clipboard.copy" content="复制">
      
        <meta name="lang:clipboard.copied" content="已复制">
      
        <meta name="lang:search.language" content="ja">
      
        <meta name="lang:search.pipeline.stopwords" content="True">
      
        <meta name="lang:search.pipeline.trimmer" content="True">
      
        <meta name="lang:search.result.none" content="没有找到符合条件的结果">
      
        <meta name="lang:search.result.one" content="找到 1 个符合条件的结果">
      
        <meta name="lang:search.result.other" content="# 个符合条件的结果">
      
        <meta name="lang:search.tokenizer" content="[\uff0c\u3002]+">
      
      <link rel="shortcut icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.0.4, mkdocs-material-4.1.0">
    
    
      
        <title>循环层 - Keras 中文文档</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/application.982221ab.css">
      
        <link rel="stylesheet" href="../../assets/stylesheets/application-palette.224b79ff.css">
      
      
        
        
        <meta name="theme-color" content="#ef5350">
      
    
    
      <script src="../../assets/javascripts/modernizr.01ccdecf.js"></script>
    
    
      
        <link href="https://fonts.gstatic.com" rel="preconnect" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700|Roboto+Mono">
        <style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
      
    
    <link rel="stylesheet" href="../../assets/fonts/material-icons.css">
    
    
    
      
        
<script>
  window.ga = window.ga || function() {
    (ga.q = ga.q || []).push(arguments)
  }
  ga.l = +new Date
  /* Setup integration and send page view */
  ga("create", "UA-61785484-1", "keras.io")
  ga("set", "anonymizeIp", true)
  ga("send", "pageview")
  /* Register handler to log search on blur */
  document.addEventListener("DOMContentLoaded", () => {
    if (document.forms.search) {
      var query = document.forms.search.query
      query.addEventListener("blur", function() {
        if (this.value) {
          var path = document.location.pathname;
          ga("send", "pageview", path + "?q=" + this.value)
        }
      })
    }
  })
</script>
<script async src="https://www.google-analytics.com/analytics.js"></script>
      
    
    
  </head>
  
    
    
    <body dir="ltr" data-md-color-primary="red" data-md-color-accent="red">
  
    <svg class="md-svg">
      <defs>
        
        
          <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448"
    viewBox="0 0 416 448" id="__github">
  <path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19-18.125
        8.5-18.125-8.5-10.75-19-3.125-20.5 3.125-20.5 10.75-19 18.125-8.5
        18.125 8.5 10.75 19 3.125 20.5zM320 304q0 10-3.125 20.5t-10.75
        19-18.125 8.5-18.125-8.5-10.75-19-3.125-20.5 3.125-20.5 10.75-19
        18.125-8.5 18.125 8.5 10.75 19 3.125 20.5zM360
        304q0-30-17.25-51t-46.75-21q-10.25 0-48.75 5.25-17.75 2.75-39.25
        2.75t-39.25-2.75q-38-5.25-48.75-5.25-29.5 0-46.75 21t-17.25 51q0 22 8
        38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0
        37.25-1.75t35-7.375 30.5-15 20.25-25.75 8-38.375zM416 260q0 51.75-15.25
        82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5-41.75
        1.125q-19.5 0-35.5-0.75t-36.875-3.125-38.125-7.5-34.25-12.875-30.25-20.25-21.5-28.75q-15.5-30.75-15.5-82.75
        0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25
        30.875q36.75-8.75 77.25-8.75 37 0 70 8 26.25-20.5
        46.75-30.25t47.25-9.75q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34
        99.5z" />
</svg>
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
    
      <a href="#_1" tabindex="1" class="md-skip">
        跳转至
      </a>
    
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="http://keras.io/zh/" title="Keras 中文文档" class="md-header-nav__button md-logo">
          
            <i class="md-icon"></i>
          
        </a>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          
            <span class="md-header-nav__topic">
              Keras 中文文档
            </span>
            <span class="md-header-nav__topic">
              循环层
            </span>
          
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
          
<div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query" data-md-state="active">
      <label class="md-icon md-search__icon" for="__search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset" tabindex="-1">
        &#xE5CD;
      </button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta">
            键入以开始搜索
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
        
      </div>
      
        <div class="md-flex__cell md-flex__cell--shrink">
          <div class="md-header-nav__source">
            


  

<a href="https://github.com/wohugb/keras-docs/" title="前往 Github 仓库" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    GitHub
  </div>
</a>
          </div>
        </div>
      
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
        
      
      
        

  

<nav class="md-tabs md-tabs--active" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  <li class="md-tabs__item">
    
      <a href="../.." title="Keras 文档" class="md-tabs__link">
        Keras 文档
      </a>
    
  </li>

      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../0-Getting-Started/0.sequential-model-guide/" title="0 Getting Started" class="md-tabs__link">
          0 Getting Started
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../1-Models/0.about-keras-models/" title="1 Models" class="md-tabs__link">
          1 Models
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../0.about-keras-layers/" title="2 Layers" class="md-tabs__link md-tabs__link--active">
          2 Layers
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../3-Preprocessing/0.sequence/" title="3 Preprocessing" class="md-tabs__link">
          3 Preprocessing
        </a>
      
    </li>
  

      
        
  
  
    <li class="md-tabs__item">
      
        <a href="../../4-Examples/" title="4 Examples" class="md-tabs__link">
          4 Examples
        </a>
      
    </li>
  

      
    </ul>
  </div>
</nav>
      
      <main class="md-main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="http://keras.io/zh/" title="Keras 中文文档" class="md-nav__button md-logo">
      
        <i class="md-icon"></i>
      
    </a>
    Keras 中文文档
  </label>
  
    <div class="md-nav__source">
      


  

<a href="https://github.com/wohugb/keras-docs/" title="前往 Github 仓库" class="md-source" data-md-source="github">
  
    <div class="md-source__icon">
      <svg viewBox="0 0 24 24" width="24" height="24">
        <use xlink:href="#__github" width="24" height="24"></use>
      </svg>
    </div>
  
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href="../.." title="Keras 文档" class="md-nav__link">
      Keras 文档
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../1.why-use-keras/" title="为什么选择 Keras？" class="md-nav__link">
      为什么选择 Keras？
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../2.losses/" title="损失函数 Losses" class="md-nav__link">
      损失函数 Losses
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../3.metrics/" title="评估标准 Metrics" class="md-nav__link">
      评估标准 Metrics
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../4.optimizers/" title="优化器 Optimizers" class="md-nav__link">
      优化器 Optimizers
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../5.activations/" title="激活函数 Activations" class="md-nav__link">
      激活函数 Activations
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../6.callbacks/" title="回调函数 Callbacks" class="md-nav__link">
      回调函数 Callbacks
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../7.datasets/" title="常用数据集 Datasets" class="md-nav__link">
      常用数据集 Datasets
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../8.applications/" title="应用 Applications" class="md-nav__link">
      应用 Applications
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../9.backend/" title="Keras 后端" class="md-nav__link">
      Keras 后端
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../90.initializers/" title="初始化 Initializers" class="md-nav__link">
      初始化 Initializers
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../91.regularizers/" title="正则化 Regularizers" class="md-nav__link">
      正则化 Regularizers
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../92.constraints/" title="约束 Constraints" class="md-nav__link">
      约束 Constraints
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../93.visualization/" title="可视化 Visualization" class="md-nav__link">
      可视化 Visualization
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../94.scikit-learn-api/" title="Scikit-Learn API 的封装器" class="md-nav__link">
      Scikit-Learn API 的封装器
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../96.utils/" title="工具" class="md-nav__link">
      工具
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../97.contributing/" title="关于 Github Issues 和 Pull Requests" class="md-nav__link">
      关于 Github Issues 和 Pull Requests
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-18" type="checkbox" id="nav-18">
    
    <label class="md-nav__link" for="nav-18">
      0 Getting Started
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-18">
        0 Getting Started
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../0-Getting-Started/0.sequential-model-guide/" title="开始使用 Keras Sequential 顺序模型" class="md-nav__link">
      开始使用 Keras Sequential 顺序模型
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../0-Getting-Started/1.functional-api-guide/" title="开始使用 Keras 函数式 API" class="md-nav__link">
      开始使用 Keras 函数式 API
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../0-Getting-Started/2.faq/" title="Keras FAQ: 常见问题解答" class="md-nav__link">
      Keras FAQ: 常见问题解答
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-19" type="checkbox" id="nav-19">
    
    <label class="md-nav__link" for="nav-19">
      1 Models
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-19">
        1 Models
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../1-Models/0.about-keras-models/" title="关于 Keras 模型" class="md-nav__link">
      关于 Keras 模型
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../1-Models/1.sequential/" title="Sequential 模型 API" class="md-nav__link">
      Sequential 模型 API
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../1-Models/2.model/" title="Model 类（函数式 API）" class="md-nav__link">
      Model 类（函数式 API）
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-20" type="checkbox" id="nav-20" checked>
    
    <label class="md-nav__link" for="nav-20">
      2 Layers
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-20">
        2 Layers
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../0.about-keras-layers/" title="关于 Keras 网络层" class="md-nav__link">
      关于 Keras 网络层
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../1.core/" title="核心网络层" class="md-nav__link">
      核心网络层
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../2.convolutional/" title="卷积层" class="md-nav__link">
      卷积层
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../3.pooling/" title="池化层" class="md-nav__link">
      池化层
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../4.local/" title="局部连接层" class="md-nav__link">
      局部连接层
    </a>
  </li>

        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="__toc">
    
      
    
    
      <label class="md-nav__link md-nav__link--active" for="__toc">
        循环层
      </label>
    
    <a href="./" title="循环层" class="md-nav__link md-nav__link--active">
      循环层
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">目录</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#rnn" title="RNN" class="md-nav__link">
    RNN
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#simplernn" title="SimpleRNN" class="md-nav__link">
    SimpleRNN
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gru" title="GRU" class="md-nav__link">
    GRU
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lstm" title="LSTM" class="md-nav__link">
    LSTM
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#convlstm2d" title="ConvLSTM2D" class="md-nav__link">
    ConvLSTM2D
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#simplernncell" title="SimpleRNNCell" class="md-nav__link">
    SimpleRNNCell
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#grucell" title="GRUCell" class="md-nav__link">
    GRUCell
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lstmcell" title="LSTMCell" class="md-nav__link">
    LSTMCell
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#cudnngru" title="CuDNNGRU" class="md-nav__link">
    CuDNNGRU
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#cudnnlstm" title="CuDNNLSTM" class="md-nav__link">
    CuDNNLSTM
  </a>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
    
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../6.embeddings/" title="嵌入层" class="md-nav__link">
      嵌入层
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../7.merge/" title="融合层" class="md-nav__link">
      融合层
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../8.advanced-activations/" title="高级激活层" class="md-nav__link">
      高级激活层
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../9.normalization/" title="标准化层" class="md-nav__link">
      标准化层
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../90.noise/" title="噪声层" class="md-nav__link">
      噪声层
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../91.wrappers/" title="层封装器" class="md-nav__link">
      层封装器
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../92.writing-your-own-keras-layers/" title="编写你自己的 Keras 层" class="md-nav__link">
      编写你自己的 Keras 层
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-21" type="checkbox" id="nav-21">
    
    <label class="md-nav__link" for="nav-21">
      3 Preprocessing
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-21">
        3 Preprocessing
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../3-Preprocessing/0.sequence/" title="序列预处理" class="md-nav__link">
      序列预处理
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../3-Preprocessing/1.text/" title="文本预处理" class="md-nav__link">
      文本预处理
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../3-Preprocessing/2.image/" title="图像预处理" class="md-nav__link">
      图像预处理
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-22" type="checkbox" id="nav-22">
    
    <label class="md-nav__link" for="nav-22">
      4 Examples
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-22">
        4 Examples
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../4-Examples/" title="经典样例" class="md-nav__link">
      经典样例
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../4-Examples/0.pretrained_word_embeddings/" title="预训练的单词嵌入" class="md-nav__link">
      预训练的单词嵌入
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../4-Examples/addition_rnn/" title="实现一个用来执行加法的序列到序列学习模型" class="md-nav__link">
      实现一个用来执行加法的序列到序列学习模型
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../4-Examples/antirectifier/" title="Antirectifier" class="md-nav__link">
      Antirectifier
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../4-Examples/babi_memnn/" title="在 bAbI 数据集上训练一个记忆网络。" class="md-nav__link">
      在 bAbI 数据集上训练一个记忆网络。
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../4-Examples/babi_rnn/" title="基于故事和问题训练两个循环神经网络。" class="md-nav__link">
      基于故事和问题训练两个循环神经网络。
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../4-Examples/cifar10_cnn/" title="在 CIFAR10 小型图像数据集上训练一个深度卷积神经网络。" class="md-nav__link">
      在 CIFAR10 小型图像数据集上训练一个深度卷积神经网络。
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../4-Examples/cifar10_cnn_capsule/" title="在 CIFAR10 小型图像数据集上训练一个简单的 CNN-Capsule Network。" class="md-nav__link">
      在 CIFAR10 小型图像数据集上训练一个简单的 CNN-Capsule Network。
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../4-Examples/cifar10_cnn_tfaugment2d/" title="Cifar10 cnn tfaugment2d" class="md-nav__link">
      Cifar10 cnn tfaugment2d
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../4-Examples/cifar10_resnet/" title="Cifar10 resnet" class="md-nav__link">
      Cifar10 resnet
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../4-Examples/class_activation_maps/" title="Class activation maps" class="md-nav__link">
      Class activation maps
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../4-Examples/conv_filter_visualization/" title="Conv filter visualization" class="md-nav__link">
      Conv filter visualization
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../4-Examples/conv_lstm/" title="Conv lstm" class="md-nav__link">
      Conv lstm
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../4-Examples/deep_dream/" title="Deep dream" class="md-nav__link">
      Deep dream
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../4-Examples/image_ocr/" title="Optical character recognition" class="md-nav__link">
      Optical character recognition
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../4-Examples/imdb_bidirectional_lstm/" title="Imdb bidirectional lstm" class="md-nav__link">
      Imdb bidirectional lstm
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../4-Examples/imdb_cnn/" title="Imdb cnn" class="md-nav__link">
      Imdb cnn
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../4-Examples/imdb_cnn_lstm/" title="Imdb cnn lstm" class="md-nav__link">
      Imdb cnn lstm
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../4-Examples/imdb_fasttext/" title="Imdb fasttext" class="md-nav__link">
      Imdb fasttext
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../4-Examples/imdb_lstm/" title="Imdb lstm" class="md-nav__link">
      Imdb lstm
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../4-Examples/lstm_seq2seq/" title="Lstm seq2seq" class="md-nav__link">
      Lstm seq2seq
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../4-Examples/lstm_seq2seq_restore/" title="Lstm seq2seq restore" class="md-nav__link">
      Lstm seq2seq restore
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../4-Examples/lstm_stateful/" title="Lstm stateful" class="md-nav__link">
      Lstm stateful
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../4-Examples/lstm_text_generation/" title="Lstm text generation" class="md-nav__link">
      Lstm text generation
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../4-Examples/mnist_acgan/" title="Mnist acgan" class="md-nav__link">
      Mnist acgan
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../4-Examples/mnist_cnn/" title="Mnist cnn" class="md-nav__link">
      Mnist cnn
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../4-Examples/mnist_dataset_api/" title="Mnist dataset api" class="md-nav__link">
      Mnist dataset api
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../4-Examples/mnist_denoising_autoencoder/" title="Mnist denoising autoencoder" class="md-nav__link">
      Mnist denoising autoencoder
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../4-Examples/mnist_hierarchical_rnn/" title="Mnist hierarchical rnn" class="md-nav__link">
      Mnist hierarchical rnn
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../4-Examples/mnist_irnn/" title="Mnist irnn" class="md-nav__link">
      Mnist irnn
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../4-Examples/mnist_mlp/" title="Mnist mlp" class="md-nav__link">
      Mnist mlp
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../4-Examples/mnist_net2net/" title="Mnist net2net" class="md-nav__link">
      Mnist net2net
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../4-Examples/mnist_siamese/" title="Mnist siamese" class="md-nav__link">
      Mnist siamese
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../4-Examples/mnist_sklearn_wrapper/" title="Mnist sklearn wrapper" class="md-nav__link">
      Mnist sklearn wrapper
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../4-Examples/mnist_swwae/" title="Mnist swwae" class="md-nav__link">
      Mnist swwae
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../4-Examples/mnist_tfrecord/" title="Mnist tfrecord" class="md-nav__link">
      Mnist tfrecord
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../4-Examples/mnist_transfer_cnn/" title="Mnist transfer cnn" class="md-nav__link">
      Mnist transfer cnn
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../4-Examples/neural_doodle/" title="Neural doodle" class="md-nav__link">
      Neural doodle
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../4-Examples/neural_style_transfer/" title="Neural style transfer" class="md-nav__link">
      Neural style transfer
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../4-Examples/reuters_mlp/" title="Reuters mlp" class="md-nav__link">
      Reuters mlp
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../4-Examples/reuters_mlp_relu_vs_selu/" title="Reuters mlp relu vs selu" class="md-nav__link">
      Reuters mlp relu vs selu
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../4-Examples/tensorboard_embeddings_mnist/" title="Tensorboard embeddings mnist" class="md-nav__link">
      Tensorboard embeddings mnist
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../4-Examples/variational_autoencoder/" title="Variational autoencoder" class="md-nav__link">
      Variational autoencoder
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../4-Examples/variational_autoencoder_deconv/" title="Variational autoencoder deconv" class="md-nav__link">
      Variational autoencoder deconv
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
    
  
  
    <label class="md-nav__title" for="__toc">目录</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#rnn" title="RNN" class="md-nav__link">
    RNN
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#simplernn" title="SimpleRNN" class="md-nav__link">
    SimpleRNN
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gru" title="GRU" class="md-nav__link">
    GRU
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lstm" title="LSTM" class="md-nav__link">
    LSTM
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#convlstm2d" title="ConvLSTM2D" class="md-nav__link">
    ConvLSTM2D
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#simplernncell" title="SimpleRNNCell" class="md-nav__link">
    SimpleRNNCell
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#grucell" title="GRUCell" class="md-nav__link">
    GRUCell
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#lstmcell" title="LSTMCell" class="md-nav__link">
    LSTMCell
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#cudnngru" title="CuDNNGRU" class="md-nav__link">
    CuDNNGRU
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#cudnnlstm" title="CuDNNLSTM" class="md-nav__link">
    CuDNNLSTM
  </a>
  
</li>
      
      
      
      
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/wohugb/keras-docs/edit/master/docs/2-Layers/5.recurrent.md" title="编辑此页" class="md-icon md-content__icon">&#xE3C9;</a>
                
                
                <h1 id="_1">循环层</h1>
<p><span style="float:right;"><a href="https://github.com/keras-team/keras/blob/master/keras/layers/recurrent.py#L237">[source]</a></span></p>
<h3 id="rnn">RNN</h3>
<pre><code class="python">keras.layers.RNN(cell, return_sequences=False, return_state=False, go_backwards=False, stateful=False, unroll=False)
</code></pre>

<p>循环神经网络层基类。</p>
<p><strong>参数</strong></p>
<ul>
<li>
<p><strong>cell</strong>: 一个 RNN 单元实例。RNN 单元是一个具有以下几项的类：</p>
</li>
<li>
<p>一个  <code>call(input_at_t, states_at_t)</code> 方法，
    它返回 <code>(output_at_t, states_at_t_plus_1)</code>。
    单元的调用方法也可以采引入可选参数 <code>constants</code>，
    详见下面的小节「关于给 RNN 传递外部常量的说明」。</p>
</li>
<li>一个  <code>state_size</code> 属性。这可以是单个整数（单个状态），
    在这种情况下，它是循环层状态的大小（应该与单元输出的大小相同）。
    这也可以是整数表示的列表/元组（每个状态一个大小）。</li>
<li>一个 <code>output_size</code> 属性。 这可以是单个整数或者是一个 TensorShape，
    它表示输出的尺寸。出于向后兼容的原因，如果此属性对于当前单元不可用，
    则该值将由 <code>state_size</code> 的第一个元素推断。</li>
</ul>
<p><code>cell</code> 也可能是 RNN 单元实例的列表，在这种情况下，RNN 的单元将堆叠在另一个单元上，实现高效的堆叠 RNN。</p>
<ul>
<li><strong>return_sequences</strong>: 布尔值。是返回输出序列中的最后一个输出，还是全部序列。</li>
<li><strong>return_state</strong>: 布尔值。除了输出之外是否返回最后一个状态。</li>
<li><strong>go_backwards</strong>: 布尔值 (默认 False)。
  如果为 True，则向后处理输入序列并返回相反的序列。</li>
<li><strong>stateful</strong>: 布尔值 (默认 False)。
  如果为 True，则批次中索引 i 处的每个样品的最后状态将用作下一批次中索引 i 样品的初始状态。</li>
<li><strong>unroll</strong>: 布尔值 (默认 False)。
  如果为 True，则网络将展开，否则将使用符号循环。
  展开可以加速 RNN，但它往往会占用更多的内存。
  展开只适用于短序列。</li>
<li><strong>input_dim</strong>: 输入的维度（整数）。
  将此层用作模型中的第一层时，此参数（或者，关键字参数 <code>input_shape</code>）是必需的。</li>
<li><strong>input_length</strong>: 输入序列的长度，在恒定时指定。
  如果你要在上游连接 <code>Flatten</code> 和  <code>Dense</code> 层，
  则需要此参数（如果没有它，无法计算全连接输出的尺寸）。
  请注意，如果循环神经网络层不是模型中的第一层，
  则需要在第一层的层级指定输入长度（例如，通过 <code>input_shape</code> 参数）。</li>
</ul>
<p><strong>输入尺寸</strong></p>
<p>3D 张量，尺寸为 <code>(batch_size, timesteps, input_dim)</code>。</p>
<p><strong>输出尺寸</strong></p>
<ul>
<li>如果 <code>return_state</code>：返回张量列表。
  第一个张量为输出。剩余的张量为最后的状态，
  每个张量的尺寸为 <code>(batch_size, units)</code>。</li>
<li>如果 <code>return_sequences</code>：返回 3D 张量，
  尺寸为 <code>(batch_size, timesteps, units)</code>。</li>
<li>否则，返回尺寸为 <code>(batch_size, units)</code> 的 2D 张量。</li>
</ul>
<p><strong>Masking</strong></p>
<p>该层支持以可变数量的时间步对输入数据进行 masking。
要将 masking 引入你的数据，请使用 <a href="../6.embeddings/">Embedding</a> 层，并将 <code>mask_zero</code> 参数设置为 <code>True</code>。</p>
<p><strong>关于在 RNN 中使用「状态（statefulness）」的说明</strong></p>
<p>你可以将 RNN 层设置为 <code>stateful</code>（有状态的），
这意味着针对一个批次的样本计算的状态将被重新用作下一批样本的初始状态。
这假定在不同连续批次的样品之间有一对一的映射。</p>
<p>为了使状态有效：</p>
<ul>
<li>在层构造器中指定 <code>stateful=True</code>。</li>
<li>为你的模型指定一个固定的批次大小，
  如果是顺序模型，为你的模型的第一层传递一个 <code>batch_input_shape=(...)</code> 参数。</li>
<li>为你的模型指定一个固定的批次大小，
  如果是顺序模型，为你的模型的第一层传递一个 <code>batch_input_shape=(...)</code>。
  如果是带有 1 个或多个 Input 层的函数式模型，为你的模型的所有第一层传递一个 <code>batch_shape=(...)</code>。
  这是你的输入的预期尺寸，<em>包括批量维度</em>。
  它应该是整数的元组，例如 <code>(32, 10, 100)</code>。</li>
<li>在调用 <code>fit()</code> 是指定 <code>shuffle=False</code>。</li>
</ul>
<p>要重置模型的状态，请在特定图层或整个模型上调用 <code>.reset_states()</code>。</p>
<p><strong>关于指定 RNN 初始状态的说明</strong></p>
<p>您可以通过使用关键字参数 <code>initial_state</code> 调用它们来符号化地指定 RNN 层的初始状态。
<code>initial_state</code> 的值应该是表示 RNN 层初始状态的张量或张量列表。</p>
<p>您可以通过调用带有关键字参数 <code>states</code> 的 <code>reset_states</code> 方法来数字化地指定 RNN 层的初始状态。
<code>states</code> 的值应该是一个代表 RNN 层初始状态的 Numpy 数组或者 Numpy 数组列表。</p>
<p><strong>关于给 RNN 传递外部常量的说明</strong></p>
<p>你可以使用 <code>RNN.__call__</code>（以及 <code>RNN.call</code>）的 <code>constants</code> 关键字参数将「外部」常量传递给单元。
这要求 <code>cell.call</code> 方法接受相同的关键字参数 <code>constants</code>。
这些常数可用于调节附加静态输入（不随时间变化）上的单元转换，也可用于注意力机制。</p>
<p><strong>例子</strong></p>
<pre><code class="python"># 首先，让我们定义一个 RNN 单元，作为网络层子类。

class MinimalRNNCell(keras.layers.Layer):

    def __init__(self, units, **kwargs):
        self.units = units
        self.state_size = units
        super(MinimalRNNCell, self).__init__(**kwargs)

    def build(self, input_shape):
        self.kernel = self.add_weight(shape=(input_shape[-1], self.units),
                                      initializer='uniform',
                                      name='kernel')
        self.recurrent_kernel = self.add_weight(
            shape=(self.units, self.units),
            initializer='uniform',
            name='recurrent_kernel')
        self.built = True

    def call(self, inputs, states):
        prev_output = states[0]
        h = K.dot(inputs, self.kernel)
        output = h + K.dot(prev_output, self.recurrent_kernel)
        return output, [output]

# 让我们在 RNN 层使用这个单元：

cell = MinimalRNNCell(32)
x = keras.Input((None, 5))
layer = RNN(cell)
y = layer(x)

# 以下是如何使用单元格构建堆叠的 RNN的方法：

cells = [MinimalRNNCell(32), MinimalRNNCell(64)]
x = keras.Input((None, 5))
layer = RNN(cells)
y = layer(x)
</code></pre>

<hr />
<p><span style="float:right;"><a href="https://github.com/keras-team/keras/blob/master/keras/layers/recurrent.py#L944">[source]</a></span></p>
<h3 id="simplernn">SimpleRNN</h3>
<pre><code class="python">keras.layers.SimpleRNN(units, activation='tanh', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0, return_sequences=False, return_state=False, go_backwards=False, stateful=False, unroll=False)
</code></pre>

<p>全连接的 RNN，其输出将被反馈到输入。</p>
<p><strong>参数</strong></p>
<ul>
<li><strong>units</strong>: 正整数，输出空间的维度。</li>
<li><strong>activation</strong>: 要使用的激活函数
  (详见 <a href="../../5.activations/">activations</a>)。
  默认：双曲正切（<code>tanh</code>）。
  如果传入 <code>None</code>，则不使用激活函数
  (即 线性激活：<code>a(x) = x</code>)。</li>
<li><strong>use_bias</strong>: 布尔值，该层是否使用偏置向量。</li>
<li><strong>kernel_initializer</strong>: <code>kernel</code> 权值矩阵的初始化器，
  用于输入的线性转换
  (详见 <a href="../../90.initializers/">initializers</a>)。</li>
<li><strong>recurrent_initializer</strong>: <code>recurrent_kernel</code> 权值矩阵
  的初始化器，用于循环层状态的线性转换
  (详见 <a href="../../90.initializers/">initializers</a>)。</li>
<li><strong>bias_initializer</strong>:偏置向量的初始化器
  (详见<a href="../../90.initializers/">initializers</a>).</li>
<li><strong>kernel_regularizer</strong>: 运用到 <code>kernel</code> 权值矩阵的正则化函数
  (详见 <a href="../../91.regularizers/">regularizer</a>)。</li>
<li><strong>recurrent_regularizer</strong>: 运用到 <code>recurrent_kernel</code> 权值矩阵的正则化函数
  (详见 <a href="../../91.regularizers/">regularizer</a>)。</li>
<li><strong>bias_regularizer</strong>: 运用到偏置向量的正则化函数
  (详见 <a href="../../91.regularizers/">regularizer</a>)。</li>
<li><strong>activity_regularizer</strong>: 运用到层输出（它的激活值）的正则化函数
  (详见 <a href="../../91.regularizers/">regularizer</a>)。</li>
<li><strong>kernel_constraint</strong>: 运用到 <code>kernel</code> 权值矩阵的约束函数
  (详见 <a href="../../92.constraints/">constraints</a>)。</li>
<li><strong>recurrent_constraint</strong>: 运用到 <code>recurrent_kernel</code> 权值矩阵的约束函数
  (详见 <a href="../../92.constraints/">constraints</a>)。</li>
<li><strong>bias_constraint</strong>: 运用到偏置向量的约束函数
  (详见 <a href="../../92.constraints/">constraints</a>)。</li>
<li><strong>dropout</strong>: 在 0 和 1 之间的浮点数。
  单元的丢弃比例，用于输入的线性转换。</li>
<li><strong>recurrent_dropout</strong>: 在 0 和 1 之间的浮点数。
  单元的丢弃比例，用于循环层状态的线性转换。</li>
<li><strong>return_sequences</strong>: 布尔值。是返回输出序列中的最后一个输出，还是全部序列。</li>
<li><strong>return_state</strong>: 布尔值。除了输出之外是否返回最后一个状态。</li>
<li><strong>go_backwards</strong>: 布尔值 (默认 False)。
  如果为 True，则向后处理输入序列并返回相反的序列。</li>
<li><strong>stateful</strong>: 布尔值 (默认 False)。
  如果为 True，则批次中索引 i 处的每个样品
  的最后状态将用作下一批次中索引 i 样品的初始状态。</li>
<li><strong>unroll</strong>: 布尔值 (默认 False)。
  如果为 True，则网络将展开，否则将使用符号循环。
  展开可以加速 RNN，但它往往会占用更多的内存。
  展开只适用于短序列。</li>
</ul>
<hr />
<p><span style="float:right;"><a href="https://github.com/keras-team/keras/blob/master/keras/layers/recurrent.py#L1482">[source]</a></span></p>
<h3 id="gru">GRU</h3>
<pre><code class="python">keras.layers.GRU(units, activation='tanh', recurrent_activation='hard_sigmoid', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0, implementation=1, return_sequences=False, return_state=False, go_backwards=False, stateful=False, unroll=False, reset_after=False)
</code></pre>

<p>门限循环单元网络（Gated Recurrent Unit） - Cho et al. 2014.</p>
<p>有两种变体。默认的是基于 1406.1078v3 的实现，同时在矩阵乘法之前将复位门应用于隐藏状态。
另一种则是基于 1406.1078v1 的实现，它包括顺序倒置的操作。</p>
<p>第二种变体与 CuDNNGRU(GPU-only) 兼容并且允许在 CPU 上进行推理。
因此它对于 <code>kernel</code> 和 <code>recurrent_kernel</code> 有可分离偏置。
使用 <code>'reset_after'=True</code> 和 <code>recurrent_activation='sigmoid'</code> 。</p>
<p><strong>参数</strong></p>
<ul>
<li><strong>units</strong>: 正整数，输出空间的维度。</li>
<li><strong>activation</strong>: 要使用的激活函数
  (详见 <a href="../../5.activations/">activations</a>)。
  默认：双曲正切 (<code>tanh</code>)。
  如果传入 <code>None</code>，则不使用激活函数
  (即 线性激活：<code>a(x) = x</code>)。</li>
<li><strong>recurrent_activation</strong>: 用于循环时间步的激活函数
  (详见 <a href="../../5.activations/">activations</a>)。
  默认：分段线性近似 sigmoid (<code>hard_sigmoid</code>)。
  如果传入 None，则不使用激活函数
  (即 线性激活：<code>a(x) = x</code>)。</li>
<li><strong>use_bias</strong>: 布尔值，该层是否使用偏置向量。</li>
<li><strong>kernel_initializer</strong>: <code>kernel</code> 权值矩阵的初始化器，
  用于输入的线性转换
  (详见 <a href="../../90.initializers/">initializers</a>)。</li>
<li><strong>recurrent_initializer</strong>: <code>recurrent_kernel</code> 权值矩阵
  的初始化器，用于循环层状态的线性转换
  (详见 <a href="../../90.initializers/">initializers</a>)。</li>
<li><strong>bias_initializer</strong>:偏置向量的初始化器
  (详见<a href="../../90.initializers/">initializers</a>).</li>
<li><strong>kernel_regularizer</strong>: 运用到 <code>kernel</code> 权值矩阵的正则化函数
  (详见 <a href="../../91.regularizers/">regularizer</a>)。</li>
<li><strong>recurrent_regularizer</strong>: 运用到 <code>recurrent_kernel</code> 权值矩阵的正则化函数
  (详见 <a href="../../91.regularizers/">regularizer</a>)。</li>
<li><strong>bias_regularizer</strong>: 运用到偏置向量的正则化函数
  (详见 <a href="../../91.regularizers/">regularizer</a>)。</li>
<li><strong>activity_regularizer</strong>: 运用到层输出（它的激活值）的正则化函数
  (详见 <a href="../../91.regularizers/">regularizer</a>)。</li>
<li><strong>kernel_constraint</strong>: 运用到 <code>kernel</code> 权值矩阵的约束函数
  (详见 <a href="../../92.constraints/">constraints</a>)。</li>
<li><strong>recurrent_constraint</strong>: 运用到 <code>recurrent_kernel</code> 权值矩阵的约束函数
  (详见 <a href="../../92.constraints/">constraints</a>)。</li>
<li><strong>bias_constraint</strong>: 运用到偏置向量的约束函数
  (详见 <a href="../../92.constraints/">constraints</a>)。</li>
<li><strong>dropout</strong>: 在 0 和 1 之间的浮点数。
  单元的丢弃比例，用于输入的线性转换。</li>
<li><strong>recurrent_dropout</strong>: 在 0 和 1 之间的浮点数。
  单元的丢弃比例，用于循环层状态的线性转换。</li>
<li><strong>implementation</strong>: 实现模式，1 或 2。
  模式 1 将把它的操作结构化为更多的小的点积和加法操作，
  而模式 2 将把它们分批到更少，更大的操作中。
  这些模式在不同的硬件和不同的应用中具有不同的性能配置文件。</li>
<li><strong>return_sequences</strong>: 布尔值。是返回输出序列中的最后一个输出，还是全部序列。</li>
<li><strong>return_state</strong>: 布尔值。除了输出之外是否返回最后一个状态。</li>
<li><strong>go_backwards</strong>: 布尔值 (默认 False)。
  如果为 True，则向后处理输入序列并返回相反的序列。</li>
<li><strong>stateful</strong>: 布尔值 (默认 False)。
  如果为 True，则批次中索引 i 处的每个样品的最后状态
  将用作下一批次中索引 i 样品的初始状态。</li>
<li><strong>unroll</strong>: 布尔值 (默认 False)。
  如果为 True，则网络将展开，否则将使用符号循环。
  展开可以加速 RNN，但它往往会占用更多的内存。
  展开只适用于短序列。</li>
<li><strong>reset_after</strong>:</li>
<li>GRU 公约 (是否在矩阵乘法之前或者之后使用重置门)。
  False =「之前」(默认)，Ture =「之后」( CuDNN 兼容)。</li>
</ul>
<p><strong>参考文献</strong></p>
<ul>
<li><a href="https://arxiv.org/abs/1406.1078">Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation</a></li>
<li><a href="https://arxiv.org/abs/1409.1259">On the Properties of Neural Machine Translation: Encoder-Decoder Approaches</a></li>
<li><a href="http://arxiv.org/abs/1412.3555v1">Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling</a></li>
<li><a href="http://arxiv.org/abs/1512.05287">A Theoretically Grounded Application of Dropout in Recurrent Neural Networks</a></li>
</ul>
<hr />
<p><span style="float:right;"><a href="https://github.com/keras-team/keras/blob/master/keras/layers/recurrent.py#L2034">[source]</a></span></p>
<h3 id="lstm">LSTM</h3>
<pre><code class="python">keras.layers.LSTM(units, activation='tanh', recurrent_activation='hard_sigmoid', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', unit_forget_bias=True, kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0, implementation=1, return_sequences=False, return_state=False, go_backwards=False, stateful=False, unroll=False)
</code></pre>

<p>长短期记忆网络层（Long Short-Term Memory） - Hochreiter 1997.</p>
<p><strong>参数</strong></p>
<ul>
<li><strong>units</strong>: 正整数，输出空间的维度。</li>
<li><strong>activation</strong>: 要使用的激活函数
  (详见 <a href="../../5.activations/">activations</a>)。
  如果传入 <code>None</code>，则不使用激活函数
  (即 线性激活：<code>a(x) = x</code>)。</li>
<li><strong>recurrent_activation</strong>: 用于循环时间步的激活函数
  (详见 <a href="../../5.activations/">activations</a>)。
  默认：分段线性近似 sigmoid (<code>hard_sigmoid</code>)。
  如果传入 <code>None</code>，则不使用激活函数
  (即 线性激活：<code>a(x) = x</code>)。</li>
<li><strong>use_bias</strong>: 布尔值，该层是否使用偏置向量。</li>
<li><strong>kernel_initializer</strong>: <code>kernel</code> 权值矩阵的初始化器，
  用于输入的线性转换
  (详见 <a href="../../90.initializers/">initializers</a>)。</li>
<li><strong>recurrent_initializer</strong>: <code>recurrent_kernel</code> 权值矩阵
  的初始化器，用于循环层状态的线性转换
  (详见 <a href="../../90.initializers/">initializers</a>)。</li>
<li><strong>bias_initializer</strong>:偏置向量的初始化器
  (详见<a href="../../90.initializers/">initializers</a>).</li>
<li><strong>unit_forget_bias</strong>: 布尔值。
  如果为 True，初始化时，将忘记门的偏置加 1。
  将其设置为 True 同时还会强制 <code>bias_initializer="zeros"</code>。
  这个建议来自 <a href="http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf">Jozefowicz et al.</a>。</li>
<li><strong>kernel_regularizer</strong>: 运用到 <code>kernel</code> 权值矩阵的正则化函数
  (详见 <a href="../../91.regularizers/">regularizer</a>)。</li>
<li><strong>recurrent_regularizer</strong>: 运用到 <code>recurrent_kernel</code> 权值矩阵的正则化函数
  (详见 <a href="../../91.regularizers/">regularizer</a>)。</li>
<li><strong>bias_regularizer</strong>: 运用到偏置向量的正则化函数
  (详见 <a href="../../91.regularizers/">regularizer</a>)。</li>
<li><strong>activity_regularizer</strong>: 运用到层输出（它的激活值）的正则化函数
  (详见 <a href="../../91.regularizers/">regularizer</a>)。</li>
<li><strong>kernel_constraint</strong>: 运用到 <code>kernel</code> 权值矩阵的约束函数
  (详见 <a href="../../92.constraints/">constraints</a>)。</li>
<li><strong>recurrent_constraint</strong>: 运用到 <code>recurrent_kernel</code> 权值矩阵的约束函数
  (详见 <a href="../../92.constraints/">constraints</a>)。</li>
<li><strong>bias_constraint</strong>: 运用到偏置向量的约束函数
  (详见 <a href="../../92.constraints/">constraints</a>)。</li>
<li><strong>dropout</strong>: 在 0 和 1 之间的浮点数。
  单元的丢弃比例，用于输入的线性转换。</li>
<li><strong>recurrent_dropout</strong>: 在 0 和 1 之间的浮点数。
  单元的丢弃比例，用于循环层状态的线性转换。</li>
<li><strong>implementation</strong>: 实现模式，1 或 2。
  模式 1 将把它的操作结构化为更多的小的点积和加法操作，
  而模式 2 将把它们分批到更少，更大的操作中。
  这些模式在不同的硬件和不同的应用中具有不同的性能配置文件。</li>
<li><strong>return_sequences</strong>: 布尔值。是返回输出序列中的最后一个输出，还是全部序列。</li>
<li><strong>return_state</strong>: 布尔值。除了输出之外是否返回最后一个状态。</li>
<li><strong>go_backwards</strong>: 布尔值 (默认 False)。
  如果为 True，则向后处理输入序列并返回相反的序列。</li>
<li><strong>stateful</strong>: 布尔值 (默认 False)。
  如果为 True，则批次中索引 i 处的每个样品的最后状态
  将用作下一批次中索引 i 样品的初始状态。</li>
<li><strong>unroll</strong>: 布尔值 (默认 False)。
  如果为 True，则网络将展开，否则将使用符号循环。
  展开可以加速 RNN，但它往往会占用更多的内存。
  展开只适用于短序列。</li>
</ul>
<p><strong>参考文献</strong></p>
<ul>
<li><a href="http://www.bioinf.jku.at/publications/older/2604.pdf">Long short-term memory</a> (original 1997 paper)</li>
<li><a href="http://www.mitpressjournals.org/doi/pdf/10.1162/089976600300015015">Learning to forget: Continual prediction with LSTM</a></li>
<li><a href="http://www.cs.toronto.edu/~graves/preprint.pdf">Supervised sequence labeling with recurrent neural networks</a></li>
<li><a href="http://arxiv.org/abs/1512.05287">A Theoretically Grounded Application of Dropout in Recurrent Neural Networks</a></li>
</ul>
<hr />
<p><span style="float:right;"><a href="https://github.com/keras-team/keras/blob/master/keras/layers/convolutional_recurrent.py#L788">[source]</a></span></p>
<h3 id="convlstm2d">ConvLSTM2D</h3>
<pre><code class="python">keras.layers.ConvLSTM2D(filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1), activation='tanh', recurrent_activation='hard_sigmoid', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', unit_forget_bias=True, kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, return_sequences=False, go_backwards=False, stateful=False, dropout=0.0, recurrent_dropout=0.0)
</code></pre>

<p>卷积 LSTM。</p>
<p>它类似于 LSTM 层，但输入变换和循环变换都是卷积的。</p>
<p><strong>参数</strong></p>
<ul>
<li><strong>filters</strong>: 整数，输出空间的维度
  （即卷积中滤波器的输出数量）。</li>
<li><strong>kernel_size</strong>: 一个整数，或者 n 个整数表示的元组或列表，
  指明卷积窗口的维度。</li>
<li><strong>strides</strong>: 一个整数，或者 n 个整数表示的元组或列表，
  指明卷积的步长。
  指定任何 stride 值 != 1 与指定 <code>dilation_rate</code> 值 != 1 两者不兼容。</li>
<li><strong>padding</strong>: <code>"valid"</code> 或 <code>"same"</code> 之一 (大小写敏感)。</li>
<li><strong>data_format</strong>: 字符串，
  <code>channels_last</code> (默认) 或 <code>channels_first</code> 之一。
  输入中维度的顺序。
  <code>channels_last</code> 对应输入尺寸为 <code>(batch, time, ..., channels)</code>，
  <code>channels_first</code> 对应输入尺寸为 <code>(batch, time, channels, ...)</code>。
  它默认为从 Keras 配置文件 <code>~/.keras/keras.json</code> 中
  找到的 <code>image_data_format</code> 值。
  如果你从未设置它，将使用 <code>"channels_last"</code>。</li>
<li><strong>dilation_rate</strong>: 一个整数，或 n 个整数的元组/列表，指定用于膨胀卷积的膨胀率。
  目前，指定任何 <code>dilation_rate</code> 值 != 1 与指定 stride 值 != 1 两者不兼容。</li>
<li><strong>activation</strong>: 要使用的激活函数
  (详见 <a href="../../5.activations/">activations</a>)。
  如果传入 None，则不使用激活函数
  (即 线性激活：<code>a(x) = x</code>)。</li>
<li><strong>recurrent_activation</strong>: 用于循环时间步的激活函数
  (详见 <a href="../../5.activations/">activations</a>)。</li>
<li><strong>use_bias</strong>: 布尔值，该层是否使用偏置向量。</li>
<li><strong>kernel_initializer</strong>: <code>kernel</code> 权值矩阵的初始化器，
  用于输入的线性转换
  (详见 <a href="../../90.initializers/">initializers</a>)。</li>
<li><strong>recurrent_initializer</strong>: <code>recurrent_kernel</code> 权值矩阵
  的初始化器，用于循环层状态的线性转换
  (详见 <a href="../../90.initializers/">initializers</a>)。</li>
<li><strong>bias_initializer</strong>:偏置向量的初始化器
  (详见<a href="../../90.initializers/">initializers</a>).</li>
<li><strong>unit_forget_bias</strong>: 布尔值。
  如果为 True，初始化时，将忘记门的偏置加 1。
  将其设置为 True 同时还会强制 <code>bias_initializer="zeros"</code>。
  这个建议来自 <a href="http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf">Jozefowicz et al.</a>。</li>
<li><strong>kernel_regularizer</strong>: 运用到 <code>kernel</code> 权值矩阵的正则化函数
  (详见 <a href="../../91.regularizers/">regularizer</a>)。</li>
<li><strong>recurrent_regularizer</strong>: 运用到 <code>recurrent_kernel</code> 权值矩阵的正则化函数
  (详见 <a href="../../91.regularizers/">regularizer</a>)。</li>
<li><strong>bias_regularizer</strong>: 运用到偏置向量的正则化函数
  (详见 <a href="../../91.regularizers/">regularizer</a>)。</li>
<li><strong>activity_regularizer</strong>: 运用到层输出（它的激活值）的正则化函数
  (详见 <a href="../../91.regularizers/">regularizer</a>)。</li>
<li><strong>kernel_constraint</strong>: 运用到 <code>kernel</code> 权值矩阵的约束函数
  (详见 <a href="../../92.constraints/">constraints</a>)。</li>
<li><strong>recurrent_constraint</strong>: 运用到 <code>recurrent_kernel</code> 权值矩阵的约束函数
  (详见 <a href="../../92.constraints/">constraints</a>)。</li>
<li><strong>bias_constraint</strong>: 运用到偏置向量的约束函数
  (详见 <a href="../../92.constraints/">constraints</a>)。</li>
<li><strong>return_sequences</strong>: 布尔值。是返回输出序列中的最后一个输出，还是全部序列。</li>
<li><strong>go_backwards</strong>: 布尔值 (默认 False)。
  如果为 True，则向后处理输入序列并返回相反的序列。</li>
<li><strong>stateful</strong>: 布尔值 (默认 False)。
  如果为 True，则批次中索引 i 处的每个样品的最后状态
  将用作下一批次中索引 i 样品的初始状态。</li>
<li><strong>dropout</strong>: 在 0 和 1 之间的浮点数。
  单元的丢弃比例，用于输入的线性转换。</li>
<li><strong>recurrent_dropout</strong>: 在 0 和 1 之间的浮点数。
  单元的丢弃比例，用于循环层状态的线性转换。</li>
</ul>
<p><strong>输入尺寸</strong></p>
<ul>
<li>如果 data_format='channels_first'，
  输入 5D 张量，尺寸为：
  <code>(samples,time, channels, rows, cols)</code>。</li>
<li>如果 data_format='channels_last'，
  输入 5D 张量，尺寸为：
  <code>(samples,time, rows, cols, channels)</code>。</li>
</ul>
<p><strong>输出尺寸</strong></p>
<ul>
<li>如果 <code>return_sequences</code>，</li>
<li>如果 data_format='channels_first'，返回 5D 张量，尺寸为：<code>(samples, time, filters, output_row, output_col)</code>。</li>
<li>如果 data_format='channels_last'，返回 5D 张量，尺寸为：<code>(samples, time, output_row, output_col, filters)</code>。</li>
<li>否则，</li>
<li>如果 data_format ='channels_first'，返回 4D 张量，尺寸为：<code>(samples, filters, output_row, output_col)</code>。</li>
<li>如果 data_format='channels_last'，返回 4D 张量，尺寸为：<code>(samples, output_row, output_col, filters)</code>。</li>
</ul>
<p>o_row 和 o_col 取决于 filter 和 padding 的尺寸。</p>
<p><strong>异常</strong></p>
<ul>
<li><strong>ValueError</strong>: 无效的构造参数。</li>
</ul>
<p><strong>参考文献</strong></p>
<ul>
<li><a href="http://arxiv.org/abs/1506.04214v1">Convolutional LSTM Network: A Machine Learning Approach for
  Precipitation Nowcasting</a>。
  当前的实现不包括单元输出的反馈回路。</li>
</ul>
<hr />
<p><span style="float:right;"><a href="https://github.com/keras-team/keras/blob/master/keras/layers/recurrent.py#L779">[source]</a></span></p>
<h3 id="simplernncell">SimpleRNNCell</h3>
<pre><code class="python">keras.layers.SimpleRNNCell(units, activation='tanh', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0)
</code></pre>

<p>SimpleRNN 的单元类。</p>
<p><strong>参数</strong></p>
<ul>
<li><strong>units</strong>: 正整数，输出空间的维度。</li>
<li><strong>activation</strong>: 要使用的激活函数
  (详见 <a href="../../5.activations/">activations</a>)。
  默认：双曲正切 (<code>tanh</code>)。
  如果传入 <code>None</code>，则不使用激活函数
  (即 线性激活：<code>a(x) = x</code>)。</li>
<li><strong>use_bias</strong>: 布尔值，该层是否使用偏置向量。</li>
<li><strong>kernel_initializer</strong>: <code>kernel</code> 权值矩阵的初始化器，
  用于输入的线性转换
  (详见 <a href="../../90.initializers/">initializers</a>)。</li>
<li><strong>recurrent_initializer</strong>: <code>recurrent_kernel</code> 权值矩阵
  的初始化器，用于循环层状态的线性转换
  (详见 <a href="../../90.initializers/">initializers</a>)。</li>
<li><strong>bias_initializer</strong>:偏置向量的初始化器
  (详见<a href="../../90.initializers/">initializers</a>).</li>
<li><strong>kernel_regularizer</strong>: 运用到 <code>kernel</code> 权值矩阵的正则化函数
  (详见 <a href="../../91.regularizers/">regularizer</a>)。</li>
<li><strong>recurrent_regularizer</strong>: 运用到 <code>recurrent_kernel</code> 权值矩阵的正则化函数
  (详见 <a href="../../91.regularizers/">regularizer</a>)。</li>
<li><strong>bias_regularizer</strong>: 运用到偏置向量的正则化函数
  (详见 <a href="../../91.regularizers/">regularizer</a>)。</li>
<li><strong>kernel_constraint</strong>: 运用到 <code>kernel</code> 权值矩阵的约束函数
  (详见 <a href="../../92.constraints/">constraints</a>)。</li>
<li><strong>recurrent_constraint</strong>: 运用到 <code>recurrent_kernel</code> 权值矩阵的约束函数
  (详见 <a href="../../92.constraints/">constraints</a>)。</li>
<li><strong>bias_constraint</strong>: 运用到偏置向量的约束函数
  (详见 <a href="../../92.constraints/">constraints</a>)。</li>
<li><strong>dropout</strong>: 在 0 和 1 之间的浮点数。
  单元的丢弃比例，用于输入的线性转换。</li>
<li><strong>recurrent_dropout</strong>: 在 0 和 1 之间的浮点数。
  单元的丢弃比例，用于循环层状态的线性转换。</li>
</ul>
<hr />
<p><span style="float:right;"><a href="https://github.com/keras-team/keras/blob/master/keras/layers/recurrent.py#L1163">[source]</a></span></p>
<h3 id="grucell">GRUCell</h3>
<pre><code class="python">keras.layers.GRUCell(units, activation='tanh', recurrent_activation='hard_sigmoid', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0, implementation=1, reset_after=False)
</code></pre>

<p>GRU 层的单元类。</p>
<p><strong>参数</strong></p>
<ul>
<li><strong>units</strong>: 正整数，输出空间的维度。</li>
<li><strong>activation</strong>: 要使用的激活函数
  (详见 <a href="../../5.activations/">activations</a>)。
  默认：双曲正切 (<code>tanh</code>)。
  如果传入 <code>None</code>，则不使用激活函数
  (即 线性激活：<code>a(x) = x</code>)。</li>
<li><strong>recurrent_activation</strong>: 用于循环时间步的激活函数
  (详见 <a href="../../5.activations/">activations</a>)。
  默认：分段线性近似 sigmoid (<code>hard_sigmoid</code>)。
  如果传入 <code>None</code>，则不使用激活函数
  (即 线性激活：<code>a(x) = x</code>)。</li>
<li><strong>use_bias</strong>: 布尔值，该层是否使用偏置向量。</li>
<li><strong>kernel_initializer</strong>: <code>kernel</code> 权值矩阵的初始化器，
  用于输入的线性转换
  (详见 <a href="../../90.initializers/">initializers</a>)。</li>
<li><strong>recurrent_initializer</strong>: <code>recurrent_kernel</code> 权值矩阵
  的初始化器，用于循环层状态的线性转换
  (详见 <a href="../../90.initializers/">initializers</a>)。</li>
<li><strong>bias_initializer</strong>:偏置向量的初始化器
  (详见<a href="../../90.initializers/">initializers</a>).</li>
<li><strong>kernel_regularizer</strong>: 运用到 <code>kernel</code> 权值矩阵的正则化函数
  (详见 <a href="../../91.regularizers/">regularizer</a>)。</li>
<li><strong>recurrent_regularizer</strong>: 运用到 <code>recurrent_kernel</code> 权值矩阵的正则化函数
  (详见 <a href="../../91.regularizers/">regularizer</a>)。</li>
<li><strong>bias_regularizer</strong>: 运用到偏置向量的正则化函数
  (详见 <a href="../../91.regularizers/">regularizer</a>)。</li>
<li><strong>kernel_constraint</strong>: 运用到 <code>kernel</code> 权值矩阵的约束函数
  (详见 <a href="../../92.constraints/">constraints</a>)。</li>
<li><strong>recurrent_constraint</strong>: 运用到 <code>recurrent_kernel</code> 权值矩阵的约束函数
  (详见 <a href="../../92.constraints/">constraints</a>)。</li>
<li><strong>bias_constraint</strong>: 运用到偏置向量的约束函数
  (详见 <a href="../../92.constraints/">constraints</a>)。</li>
<li><strong>dropout</strong>: 在 0 和 1 之间的浮点数。
  单元的丢弃比例，用于输入的线性转换。</li>
<li><strong>recurrent_dropout</strong>: 在 0 和 1 之间的浮点数。
  单元的丢弃比例，用于循环层状态的线性转换。</li>
<li><strong>implementation</strong>: 实现模式，1 或 2。
  模式 1 将把它的操作结构化为更多的小的点积和加法操作，
  而模式 2 将把它们分批到更少，更大的操作中。
  这些模式在不同的硬件和不同的应用中具有不同的性能配置文件。</li>
<li><strong>reset_after</strong>:</li>
<li>GRU 公约 (是否在矩阵乘法之前或者之后使用重置门)。
  False = "before" (默认)，Ture = "after" ( CuDNN 兼容)。</li>
<li><strong>reset_after</strong>: GRU convention (whether to apply reset gate after or
  before matrix multiplication). False = "before" (default),
  True = "after" (CuDNN compatible).</li>
</ul>
<hr />
<p><span style="float:right;"><a href="https://github.com/keras-team/keras/blob/master/keras/layers/recurrent.py#L1756">[source]</a></span></p>
<h3 id="lstmcell">LSTMCell</h3>
<pre><code class="python">keras.layers.LSTMCell(units, activation='tanh', recurrent_activation='hard_sigmoid', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', unit_forget_bias=True, kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0, implementation=1)
</code></pre>

<p>LSTM 层的单元类。</p>
<p><strong>参数</strong></p>
<ul>
<li><strong>units</strong>: 正整数，输出空间的维度。</li>
<li><strong>activation</strong>: 要使用的激活函数
  (详见 <a href="../../5.activations/">activations</a>)。
  默认：双曲正切（<code>tanh</code>）。
  如果传入 <code>None</code>，则不使用激活函数
  (即 线性激活：<code>a(x) = x</code>)。</li>
<li><strong>recurrent_activation</strong>: 用于循环时间步的激活函数
  (详见 <a href="../../5.activations/">activations</a>)。
  默认：分段线性近似 sigmoid (<code>hard_sigmoid</code>)。</li>
<li><strong>use_bias</strong>: 布尔值，该层是否使用偏置向量。</li>
<li><strong>kernel_initializer</strong>: <code>kernel</code> 权值矩阵的初始化器，
  用于输入的线性转换
  (详见 <a href="../../90.initializers/">initializers</a>)。</li>
<li><strong>recurrent_initializer</strong>: <code>recurrent_kernel</code> 权值矩阵
  的初始化器，用于循环层状态的线性转换
  (详见 <a href="../../90.initializers/">initializers</a>)。</li>
<li><strong>bias_initializer</strong>:偏置向量的初始化器
  (详见<a href="../../90.initializers/">initializers</a>).</li>
<li><strong>unit_forget_bias</strong>: 布尔值。
  如果为 True，初始化时，将忘记门的偏置加 1。
  将其设置为 True 同时还会强制 <code>bias_initializer="zeros"</code>。
  这个建议来自 <a href="http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf">Jozefowicz et al.</a>。</li>
<li><strong>kernel_regularizer</strong>: 运用到 <code>kernel</code> 权值矩阵的正则化函数
  (详见 <a href="../../91.regularizers/">regularizer</a>)。</li>
<li><strong>recurrent_regularizer</strong>: 运用到 <code>recurrent_kernel</code> 权值矩阵的正则化函数
  (详见 <a href="../../91.regularizers/">regularizer</a>)。</li>
<li><strong>bias_regularizer</strong>: 运用到偏置向量的正则化函数
  (详见 <a href="../../91.regularizers/">regularizer</a>)。</li>
<li><strong>kernel_constraint</strong>: 运用到 <code>kernel</code> 权值矩阵的约束函数
  (详见 <a href="../../92.constraints/">constraints</a>)。</li>
<li><strong>recurrent_constraint</strong>: 运用到 <code>recurrent_kernel</code> 权值矩阵的约束函数
  (详见 <a href="../../92.constraints/">constraints</a>)。</li>
<li><strong>bias_constraint</strong>: 运用到偏置向量的约束函数
  (详见 <a href="../../92.constraints/">constraints</a>)。</li>
<li><strong>dropout</strong>: 在 0 和 1 之间的浮点数。
  单元的丢弃比例，用于输入的线性转换。</li>
<li><strong>recurrent_dropout</strong>: 在 0 和 1 之间的浮点数。
  单元的丢弃比例，用于循环层状态的线性转换。</li>
<li><strong>implementation</strong>: 实现模式，1 或 2。
  模式 1 将把它的操作结构化为更多的小的点积和加法操作，
  而模式 2 将把它们分批到更少，更大的操作中。
  这些模式在不同的硬件和不同的应用中具有不同的性能配置文件。</li>
</ul>
<hr />
<p><span style="float:right;"><a href="https://github.com/keras-team/keras/blob/master/keras/layers/cudnn_recurrent.py#L135">[source]</a></span></p>
<h3 id="cudnngru">CuDNNGRU</h3>
<pre><code class="python">keras.layers.CuDNNGRU(units, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, return_sequences=False, return_state=False, stateful=False)
</code></pre>

<p>由 <a href="https://developer.nvidia.com/cudnn">CuDNN</a> 支持的快速 GRU 实现。</p>
<p>只能以 TensorFlow 后端运行在 GPU 上。</p>
<p><strong>参数</strong></p>
<ul>
<li><strong>units</strong>: 正整数，输出空间的维度。</li>
<li><strong>kernel_initializer</strong>: <code>kernel</code> 权值矩阵的初始化器，
  用于输入的线性转换
  (详见 <a href="../../90.initializers/">initializers</a>)。</li>
<li><strong>recurrent_initializer</strong>: <code>recurrent_kernel</code> 权值矩阵
  的初始化器，用于循环层状态的线性转换
  (详见 <a href="../../90.initializers/">initializers</a>)。</li>
<li><strong>bias_initializer</strong>:偏置向量的初始化器
  (详见<a href="../../90.initializers/">initializers</a>).</li>
<li><strong>kernel_regularizer</strong>: 运用到 <code>kernel</code> 权值矩阵的正则化函数
  (详见 <a href="../../91.regularizers/">regularizer</a>)。</li>
<li><strong>recurrent_regularizer</strong>: 运用到 <code>recurrent_kernel</code> 权值矩阵的正则化函数
  (详见 <a href="../../91.regularizers/">regularizer</a>)。</li>
<li><strong>bias_regularizer</strong>: 运用到偏置向量的正则化函数
  (详见 <a href="../../91.regularizers/">regularizer</a>)。</li>
<li><strong>activity_regularizer</strong>: Regularizer function applied to
  the output of the layer (its "activation").
  (see <a href="../../91.regularizers/">regularizer</a>).</li>
<li><strong>kernel_constraint</strong>: 运用到 <code>kernel</code> 权值矩阵的约束函数
  (详见 <a href="../../92.constraints/">constraints</a>)。</li>
<li><strong>recurrent_constraint</strong>: 运用到 <code>recurrent_kernel</code> 权值矩阵的约束函数
  (详见 <a href="../../92.constraints/">constraints</a>)。</li>
<li><strong>bias_constraint</strong>: 运用到偏置向量的约束函数
  (详见 <a href="../../92.constraints/">constraints</a>)。</li>
<li><strong>return_sequences</strong>: 布尔值。是返回输出序列中的最后一个输出，还是全部序列。</li>
<li><strong>return_state</strong>: 布尔值。除了输出之外是否返回最后一个状态。</li>
<li><strong>stateful</strong>: 布尔值 (默认 False)。
  如果为 True，则批次中索引 i 处的每个样品的最后状态
  将用作下一批次中索引 i 样品的初始状态。</li>
</ul>
<hr />
<p><span style="float:right;"><a href="https://github.com/keras-team/keras/blob/master/keras/layers/cudnn_recurrent.py#L328">[source]</a></span></p>
<h3 id="cudnnlstm">CuDNNLSTM</h3>
<pre><code class="python">keras.layers.CuDNNLSTM(units, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', unit_forget_bias=True, kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, return_sequences=False, return_state=False, stateful=False)
</code></pre>

<p>由 <a href="https://developer.nvidia.com/cudnn">CuDNN</a> 支持的快速 LSTM 实现。</p>
<p>只能以 TensorFlow 后端运行在 GPU 上。</p>
<p><strong>参数</strong></p>
<ul>
<li><strong>units</strong>: 正整数，输出空间的维度。</li>
<li><strong>kernel_initializer</strong>: <code>kernel</code> 权值矩阵的初始化器，用于输入的线性转换(详见 <a href="../../90.initializers/">initializers</a>)。</li>
<li><strong>unit_forget_bias</strong>: 布尔值。
  如果为 True，初始化时，将忘记门的偏置加 1。
  将其设置为 True 同时还会强制 <code>bias_initializer="zeros"</code>。
  这个建议来自 <a href="http://www.jmlr.org/proceedings/papers/v37/jozefowicz15.pdf">Jozefowicz et al.</a>。</li>
<li><strong>recurrent_initializer</strong>: <code>recurrent_kernel</code> 权值矩阵
  的初始化器，用于循环层状态的线性转换
  (详见 <a href="../../90.initializers/">initializers</a>)。</li>
<li><strong>bias_initializer</strong>:偏置向量的初始化器
  (详见<a href="../../90.initializers/">initializers</a>).</li>
<li><strong>kernel_regularizer</strong>: 运用到 <code>kernel</code> 权值矩阵的正则化函数
  (详见 <a href="../../91.regularizers/">regularizer</a>)。</li>
<li><strong>recurrent_regularizer</strong>: 运用到 <code>recurrent_kernel</code> 权值矩阵的正则化函数
  (详见 <a href="../../91.regularizers/">regularizer</a>)。</li>
<li><strong>bias_regularizer</strong>: 运用到偏置向量的正则化函数
  (详见 <a href="../../91.regularizers/">regularizer</a>)。</li>
<li><strong>activity_regularizer</strong>: 运用到层输出（它的激活值）的正则化函数
  (详见 <a href="../../91.regularizers/">regularizer</a>)。</li>
<li><strong>kernel_constraint</strong>: 运用到 <code>kernel</code> 权值矩阵的约束函数
  (详见 <a href="../../92.constraints/">constraints</a>)。</li>
<li><strong>recurrent_constraint</strong>: 运用到 <code>recurrent_kernel</code> 权值矩阵的约束函数
  (详见 <a href="../../92.constraints/">constraints</a>)。</li>
<li><strong>bias_constraint</strong>: 运用到偏置向量的约束函数
  (详见 <a href="../../92.constraints/">constraints</a>)。</li>
<li><strong>return_sequences</strong>: 布尔值。是返回输出序列中的最后一个输出，还是全部序列。</li>
<li><strong>return_state</strong>: 布尔值。除了输出之外是否返回最后一个状态。</li>
<li><strong>stateful</strong>: 布尔值 (默认 False)。
  如果为 True，则批次中索引 i 处的每个样品的最后状态
  将用作下一批次中索引 i 样品的初始状态。</li>
</ul>
                
                  
                
              
              
                


              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href="../4.local/" title="局部连接层" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  后退
                </span>
                局部连接层
              </span>
            </div>
          </a>
        
        
          <a href="../6.embeddings/" title="嵌入层" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  前进
                </span>
                嵌入层
              </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        powered by
        <a href="https://www.mkdocs.org">MkDocs</a>
        and
        <a href="https://squidfunk.github.io/mkdocs-material/">
          Material for MkDocs</a>
      </div>
      
  <div class="md-footer-social">
    <link rel="stylesheet" href="../../assets/fonts/font-awesome.css">
    
      <a href="http://wohugb.github.io" class="md-footer-social__link fa fa-globe"></a>
    
      <a href="https://github.com/wohugb" class="md-footer-social__link fa fa-github-alt"></a>
    
      <a href="https://twitter.com/wohugb" class="md-footer-social__link fa fa-twitter"></a>
    
      <a href="https://linkedin.com/in/wohugb" class="md-footer-social__link fa fa-linkedin"></a>
    
  </div>

    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../../assets/javascripts/application.2ba8dec4.js"></script>
      
        
        
          
          <script src="../../assets/javascripts/lunr/lunr.stemmer.support.js"></script>
          
            
              
                <script src="../../assets/javascripts/lunr/tinyseg.js"></script>
              
              
                <script src="../../assets/javascripts/lunr/lunr.ja.js"></script>
              
            
          
          
        
      
      <script>app.initialize({version:"1.0.4",url:{base:"../.."}})</script>
      
    
  </body>
</html>